{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGJb1ScIJE-J"
      },
      "outputs": [],
      "source": [
        "# Google Colabでライブラリをアップロードする\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FI3b2MALJQG9"
      },
      "outputs": [],
      "source": [
        "# Google Colabでドライブのデータを使う\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5P9aOSopJUiL"
      },
      "outputs": [],
      "source": [
        "# Google Colabでライブラリをインストールする\n",
        "!pip install japanize_matplotlib bottleneck tslearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1Lq-ZkyCJJbu"
      },
      "outputs": [],
      "source": [
        "# 自作関数\n",
        "import MasterResearchFunction as mr\n",
        "\n",
        "# 基本ライブラリ\n",
        "import os, re, csv, math, statistics\n",
        "from datetime import datetime, timedelta\n",
        "from decimal import Decimal\n",
        "import pickle\n",
        "\n",
        "# 数値計算とデータ処理\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import bottleneck as bn\n",
        "\n",
        "# 機械学習ライブラリ\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# ディープラーニングライブラリ\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Activation, Conv1D, MaxPooling1D, Flatten\n",
        "\n",
        "# プロットと可視化\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import japanize_matplotlib\n",
        "\n",
        "# その他のライブラリ\n",
        "from scipy import signal, stats\n",
        "from scipy.signal import savgol_filter\n",
        "from scipy.spatial.distance import euclidean\n",
        "from scipy.interpolate import interp1d\n",
        "from tslearn.metrics import dtw_path\n",
        "from fastdtw import fastdtw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# テスト用のデータを定義\n",
        "G = [1, 2, 0, 2, 1, 2, 4, 2, 1, 0, 2, 0, 2, 0, 2, 4, 2, 1, 1, 4, 3, 2, 1, 2, 4, 0, 2, 1, 1, 2]  # 対象の時間シリーズデータ\n",
        "QG = [1, 2, 1]  # クエリ時間シリーズデータ\n",
        "Th = 1  # しきい値\n",
        "\n",
        "segments = mr.spring(G, QG, Th)\n",
        "\n",
        "print(\"検出されたセグメント:\")\n",
        "for seg in segments:\n",
        "    print(f\"開始位置: {seg[0]}, 累積距離: {seg[1]}, 開始時刻: {seg[2]}, 終了時刻: {seg[3]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSPIQYV9JE-O"
      },
      "outputs": [],
      "source": [
        "#Apple Watchのモーションデータの読み込み\n",
        "a_yuuma_motion_data = mr.process_apple_watch_csv(\"datasets/yuuma/20240604/yuuma_motion.csv\")\n",
        "b_sakamoto_motion_data = mr.process_apple_watch_csv(\"datasets/sakamoto/20240604/sakamoto_motion.csv\")\n",
        "c_watabe_motion_data = mr.process_apple_watch_csv(\"datasets/watabe/20240605/watabe_motion.csv\")\n",
        "d_nakazawa_motion_data = mr.process_apple_watch_csv(\"datasets/nakazawa/20240606/nakazawa_motion.csv\")\n",
        "e_okede_motion_data = mr.process_apple_watch_csv(\"datasets/okeda/20240607/okeda_motion.csv\")\n",
        "# a_yuuma_motion_data = mr.process_apple_watch_csv(\"/content/drive/MyDrive/datasets/yuuma/20240604/yuuma_motion.csv\")\n",
        "# b_sakamoto_motion_data = mr.process_apple_watch_csv(\"/content/drive/MyDrive/datasets/sakamoto/20240604/sakamoto_motion.csv\")\n",
        "# c_watabe_motion_data = mr.process_apple_watch_csv(\"/content/drive/MyDrive/datasets/watabe/20240605/watabe_motion.csv\")\n",
        "# d_nakazawa_motion_data = mr.process_apple_watch_csv(\"/content/drive/MyDrive/datasets/nakazawa/20240606/nakazawa_motion.csv\")\n",
        "# e_okeda_motion_data = mr.process_apple_watch_csv(\"/content/drive/MyDrive/datasets/okeda/20240607/okeda_motion.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwuLVlktIfm9"
      },
      "outputs": [],
      "source": [
        "#Tobiiのモーションデータの読み込み\n",
        "a_yuuma_eye_data = mr.process_tobii_csv(\"datasets/yuuma/20240604/yuuma_eye.csv\")\n",
        "b_sakamoto_eye_data = mr.process_tobii_csv(\"datasets/sakamoto/20240604/sakamoto_eye.csv\")\n",
        "c_watabe_eye_data = mr.process_tobii_csv(\"datasets/watabe/20240605/watabe_eye.csv\")\n",
        "d_nakazawa_eye_data = mr.process_tobii_csv(\"datasets/nakazawa/20240606/nakazawa_eye.csv\")\n",
        "e_okeda_eye_data = mr.process_tobii_csv(\"datasets/okeda/20240607/okeda_eye.csv\")\n",
        "# a_yuuma_eye_data = mr.process_tobii_csv(\"/content/drive/MyDrive/datasets/yuuma/20240604/yuuma_eye.csv\")\n",
        "# b_sakamoto_eye_data = mr.process_tobii_csv(\"/content/drive/MyDrive/datasets/sakamoto/20240604/sakamoto_eye.csv\")\n",
        "# c_watabe_eye_data = mr.process_tobii_csv(\"/content/drive/MyDrive/datasets/watabe/20240605/watabe_eye.csv\")\n",
        "# d_nakazawa_eye_data = mr.process_tobii_csv(\"/content/drive/MyDrive/datasets/nakazawa/20240606/nakazawa_eye.csv\")\n",
        "# e_okeda_eye_data = mr.process_tobii_csv(\"/content/drive/MyDrive/datasets/okeda/20240607/okeda_eye.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOEsc9-3fnXT"
      },
      "outputs": [],
      "source": [
        "#a_yuumaくんの教師データ読み込み\n",
        "a_yuuma_check = mr.process_all_apple_watch_csv_in_directory(\"datasets/yuuma/train_gesture/check\")\n",
        "a_yuuma_circle = mr.process_all_apple_watch_csv_in_directory(\"datasets/yuuma/train_gesture/circle\")\n",
        "a_yuuma_cross = mr.process_all_apple_watch_csv_in_directory(\"datasets/yuuma/train_gesture/cross(new)\")\n",
        "a_yuuma_tri = mr.process_all_apple_watch_csv_in_directory(\"datasets/yuuma/train_gesture/tri\")\n",
        "# a_yuuma_check = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/yuuma/train_gesture/check\")\n",
        "# a_yuuma_circle = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/yuuma/train_gesture/circle\")\n",
        "# a_yuuma_cross = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/yuuma/train_gesture/cross(new)\")\n",
        "# a_yuuma_tri = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/yuuma/train_gesture/tri\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uK2kISJYI71I"
      },
      "outputs": [],
      "source": [
        "#b_sakamotoくんの教師データ読み込み\n",
        "b_sakamoto_check = mr.process_all_apple_watch_csv_in_directory(\"datasets/sakamoto/train_gesture(old)/check\")\n",
        "b_sakamoto_circle = mr.process_all_apple_watch_csv_in_directory(\"datasets/sakamoto/train_gesture(old)/circle\")\n",
        "b_sakamoto_cross = mr.process_all_apple_watch_csv_in_directory(\"datasets/sakamoto/train_gesture(old)/cross\")\n",
        "b_sakamoto_tri = mr.process_all_apple_watch_csv_in_directory(\"datasets/sakamoto/train_gesture(old)/tri\")\n",
        "# b_sakamoto_check = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/sakamoto/train_gesture(old)/check\")\n",
        "# b_sakamoto_circle = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/sakamoto/train_gesture(old)/circle\")\n",
        "# b_sakamoto_cross = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/sakamoto/train_gesture(old)/cross\")\n",
        "# b_sakamoto_tri = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/sakamoto/train_gesture(old)/tri\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J3r6Flc4EsT"
      },
      "outputs": [],
      "source": [
        "#b_sakamotoくんの教師データ読み込み\n",
        "b_sakamoto_check = mr.process_all_apple_watch_csv_in_directory(\"datasets/sakamoto/train_gesture(new)/check\")\n",
        "b_sakamoto_circle = mr.process_all_apple_watch_csv_in_directory(\"datasets/sakamoto/train_gesture(new)/circle\")\n",
        "b_sakamoto_cross = mr.process_all_apple_watch_csv_in_directory(\"datasets/sakamoto/train_gesture(new)/cross\")\n",
        "b_sakamoto_tri = mr.process_all_apple_watch_csv_in_directory(\"datasets/sakamoto/train_gesture(new)/tri\")\n",
        "# b_sakamoto_check = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/sakamoto/train_gesture(new)/check\")\n",
        "# b_sakamoto_circle = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/sakamoto/train_gesture(new)/circle\")\n",
        "# b_sakamoto_cross = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/sakamoto/train_gesture(new)/cross\")\n",
        "# b_sakamoto_tri = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/sakamoto/train_gesture(new)/tri\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diEoQTluAkuW"
      },
      "outputs": [],
      "source": [
        "#c_watabeくんの教師データ読み込み\n",
        "c_watabe_check = mr.process_all_apple_watch_csv_in_directory(\"datasets/watabe/train_gesture/check\")\n",
        "c_watabe_circle = mr.process_all_apple_watch_csv_in_directory(\"datasets/watabe/train_gesture/circle\")\n",
        "c_watabe_cross = mr.process_all_apple_watch_csv_in_directory(\"datasets/watabe/train_gesture/cross\")\n",
        "c_watabe_tri = mr.process_all_apple_watch_csv_in_directory(\"datasets/watabe/train_gesture/tri\")\n",
        "# c_watabe_check = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/watabe/train_gesture/check\")\n",
        "# c_watabe_circle = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/watabe/train_gesture/circle\")\n",
        "# c_watabe_cross = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/watabe/train_gesture/cross\")\n",
        "# c_watabe_tri = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/watabe/train_gesture/tri\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lE7CC2oFKDi8"
      },
      "outputs": [],
      "source": [
        "#d_nakazawaくんの教師データ読み込み\n",
        "d_nakazawa_check = mr.process_all_apple_watch_csv_in_directory(\"datasets/nakazawa/train_gesture/check\")\n",
        "d_nakazawa_circle = mr.process_all_apple_watch_csv_in_directory(\"datasets/nakazawa/train_gesture/circle\")\n",
        "d_nakazawa_cross = mr.process_all_apple_watch_csv_in_directory(\"datasets/nakazawa/train_gesture/cross\")\n",
        "d_nakazawa_tri = mr.process_all_apple_watch_csv_in_directory(\"datasets/nakazawa/train_gesture/tri\")\n",
        "# d_nakazawa_check = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/nakazawa/train_gesture/check\")\n",
        "# d_nakazawa_circle = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/nakazawa/train_gesture/circle\")\n",
        "# d_nakazawa_cross = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/nakazawa/train_gesture/cross\")\n",
        "# d_nakazawa_tri = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/nakazawa/train_gesture/tri\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrS9POJEKLrV"
      },
      "outputs": [],
      "source": [
        "#e_okedaくんの教師データ読み込み\n",
        "e_okeda_check = mr.process_all_apple_watch_csv_in_directory(\"datasets/okeda/train_gesture/check\")\n",
        "e_okeda_circle = mr.process_all_apple_watch_csv_in_directory(\"datasets/okeda/train_gesture/circle\")\n",
        "e_okeda_cross = mr.process_all_apple_watch_csv_in_directory(\"datasets/okeda/train_gesture/cross\")\n",
        "e_okeda_tri = mr.process_all_apple_watch_csv_in_directory(\"datasets/okeda/train_gesture/tri\")\n",
        "# e_okeda_check = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/okeda/train_gesture/check\")\n",
        "# e_okeda_circle = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/okeda/train_gesture/circle\")\n",
        "# e_okeda_cross = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/okeda/train_gesture/cross\")\n",
        "# e_okeda_tri = mr.process_all_apple_watch_csv_in_directory(\"/content/drive/MyDrive/datasets/okeda/train_gesture/tri\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 723,
      "metadata": {},
      "outputs": [],
      "source": [
        "motion_data = mr.process_apple_watch_csv('datasets/new/watabe/motion/watabe_eye_circle.csv')\n",
        "#train_data = mr.process_all_apple_watch_csv_in_directory('/Users/hinase/Downloads/circle')\n",
        "eye_data = mr.process_tobii_csv('/Users/hinase/Downloads/folder2/watabe_circle.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eye_data[\"Timestamp\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "motion_data[\"Timestamp\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 726,
      "metadata": {},
      "outputs": [],
      "source": [
        "#hinase_circle_seg = mr.three_axis_spring(motion_data, train_data, [5, 5, 5], 'acc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 727,
      "metadata": {},
      "outputs": [],
      "source": [
        "Hz = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final = mr.filter_and_combine_segments(hinase_circle_seg, Hz, 0.75, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 730,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_true_intervals(df):\n",
        "    # 'Marking' カラムがTrueとなっている箇所を抽出\n",
        "    true_intervals = []\n",
        "    start_index = None\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        if row['Marking']:\n",
        "            if start_index is None:\n",
        "                start_index = index\n",
        "        else:\n",
        "            if start_index is not None:\n",
        "                true_intervals.append((start_index, index - 1))\n",
        "                start_index = None\n",
        "\n",
        "    # 最後のTrueの区間がデータフレームの最後まで続く場合\n",
        "    if start_index is not None:\n",
        "        true_intervals.append((start_index, df.index[-1]))\n",
        "\n",
        "    return true_intervals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 731,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = find_true_intervals(motion_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 733,
      "metadata": {},
      "outputs": [],
      "source": [
        "b = []\n",
        "for i in range(len(a)):\n",
        "  b.append([a[i][0]+20, a[i][1]-40])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(b)):\n",
        "  print(b[i][1] - b[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 656,
      "metadata": {},
      "outputs": [],
      "source": [
        "del b[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 659,
      "metadata": {},
      "outputs": [],
      "source": [
        "c = []\n",
        "for i in range(len(b)):\n",
        "  c.append([motion_data[\"Timestamp\"][b[i][0]], motion_data[\"Timestamp\"][b[i][1]]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 各範囲内のデータを格納するリストを用意します\n",
        "result = []\n",
        "# cの各行に対してループを回します\n",
        "for start_time, end_time in c:\n",
        "    # 範囲内のデータを抽出するためのマスクを作成します\n",
        "    mask = (eye_data[\"Timestamp\"] >= start_time) & (eye_data[\"Timestamp\"] <= end_time)\n",
        "    # マスクを適用してデータを抽出します\n",
        "    data_in_range = eye_data.loc[mask]\n",
        "    # 結果をリストに追加します\n",
        "    result.append(data_in_range)\n",
        "\n",
        "# 結果を確認します\n",
        "for idx, data in enumerate(result):\n",
        "    print(f\"範囲 {idx+1}:\")\n",
        "    print(data)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 663,
      "metadata": {},
      "outputs": [],
      "source": [
        "# resultがリストである場合\n",
        "first_20_results = result[0:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "first_20_results[19]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 665,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pickleファイルに出力する\n",
        "with open('/Users/hinase/Downloads/kotera_check_eye.pkl', 'wb') as f:\n",
        "    pickle.dump(first_20_results, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 938,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "names = ['kawano', 'sakamoto', 'watabe', 'nakazawa', 'kotera']\n",
        "#names = ['sakamoto', 'watabe']\n",
        "\n",
        "labels = ['circle', 'cross', 'tri', 'check']\n",
        "\n",
        "# 削除するカラムのリスト\n",
        "columns_to_drop = [\n",
        "    'Sensor', 'Participant name', 'Event', 'Event value',\n",
        "    'Eye movement type', 'Eye movement type index', 'Ungrouped', 'Timestamp',\n",
        "    'Validity left', 'Validity right', 'Gaze event duration', 'Gaze2D_Distance',\n",
        "    'Fixation_Distance', 'Gaze3D_Distance', 'Pupil_Diameter_Change',\n",
        "    'GazeDirection_Distance', 'PupilPosition_Distance'\n",
        "]\n",
        "\n",
        "for name in names:\n",
        "    eye_data = []\n",
        "    for label in labels:\n",
        "        filename = f'/Users/hinase/Downloads/{name}_{label}_eye.pkl'\n",
        "        with open(filename, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            eye_data.extend(data)\n",
        "    # 指定されたカラムを削除\n",
        "    processed_data = []\n",
        "    for df in eye_data:\n",
        "        processed_df = df.drop(columns=columns_to_drop)\n",
        "        processed_data.append(processed_df)\n",
        "    # 各人物ごとのデータを変数に保存\n",
        "    globals()[f'{name}_eye'] = processed_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 939,
      "metadata": {},
      "outputs": [],
      "source": [
        "# リスト内包表記で一度にリストを作成\n",
        "for name in names:\n",
        "  label = [s for s in ['circle', 'cross', 'tri', 'check'] for _ in range(20)]\n",
        "  globals()[f'{name}_label'] = label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "kotera_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 既に names リストが定義されていると仮定します\n",
        "X = []\n",
        "label = []\n",
        "\n",
        "for name in names:\n",
        "    eye_data = globals()[f'{name}_eye']     # シーケンスのリスト\n",
        "    labels = globals()[f'{name}_label']     # 対応するラベルのリスト\n",
        "\n",
        "    for seq, lbl in zip(eye_data, labels):\n",
        "        # シーケンスが空でないか確認\n",
        "        if seq is not None and len(seq) > 0:\n",
        "            X.append(seq)\n",
        "            label.append(lbl)\n",
        "        else:\n",
        "            print(f\"{name} のシーケンスが空です。対応するラベルをスキップします。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 942,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split#データ分割用\n",
        "from sklearn.ensemble import RandomForestClassifier#ランダムフォレスト\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X[7].columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 973,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = nakazawa_eye\n",
        "label = nakazawa_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 974,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Masking, LSTM, Dense\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_filled = []\n",
        "X_scaled = []\n",
        "for idx, sequence in enumerate(X):\n",
        "    df = pd.DataFrame(sequence)\n",
        "    # 欠損値の補間と補完\n",
        "    df = df.interpolate(method='linear', limit_direction='both', axis=0)\n",
        "    df = df.fillna(method='ffill')\n",
        "    df = df.fillna(method='bfill')\n",
        "    # 残る NaN を 0 で埋める\n",
        "    if df.isnull().values.any():\n",
        "        print(f\"シーケンス {idx} にまだ NaN が存在します。0 で埋めます。\")\n",
        "        df = df.fillna(0)\n",
        "    # データ型を数値型に変換（必要に応じて）\n",
        "    df = df.apply(pd.to_numeric, errors='coerce')\n",
        "    X_filled.append(df.values)\n",
        "\n",
        "# スケーリング前に NaN をチェック\n",
        "for idx, sequence in enumerate(X_filled):\n",
        "    if np.isnan(sequence).any():\n",
        "        print(f\"シーケンス {idx} に NaN が残っています。スケーリングをスキップします。\")\n",
        "        continue\n",
        "    if sequence.shape[0] > 0:\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled.append(scaler.fit_transform(sequence))\n",
        "    else:\n",
        "        print(f\"シーケンス {idx} は空です。スケーリングをスキップします。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. ラベルのエンコーディング\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(label)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "y_categorical = to_categorical(y_encoded, num_classes=num_classes)\n",
        "\n",
        "# 2. データの分割（パディングの前に行う）\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "    X_scaled, y_categorical, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# 3. 訓練データとテストデータでそれぞれ最大シーケンス長を計算\n",
        "max_length_train = max(len(seq) for seq in X_train_raw)\n",
        "max_length_test = max(len(seq) for seq in X_test_raw)\n",
        "max_length = max(max_length_train, max_length_test)\n",
        "\n",
        "# 4. シーケンスのパディング\n",
        "X_train_padded = pad_sequences(X_train_raw, maxlen=max_length, padding='post', value=0.0, dtype='float32')\n",
        "X_test_padded = pad_sequences(X_test_raw, maxlen=max_length, padding='post', value=0.0, dtype='float32')\n",
        "\n",
        "# 5. パディング後のデータに NaN が含まれていないか確認\n",
        "print('NaN in X_train_padded:', np.isnan(X_train_padded).any())\n",
        "print('NaN in X_test_padded:', np.isnan(X_test_padded).any())\n",
        "\n",
        "# 必要に応じて NaN を 0 で置換\n",
        "if np.isnan(X_train_padded).any():\n",
        "    X_train_padded = np.nan_to_num(X_train_padded, nan=0.0)\n",
        "if np.isnan(X_test_padded).any():\n",
        "    X_test_padded = np.nan_to_num(X_test_padded, nan=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 特徴量数を取得\n",
        "num_features = X_train.shape[2]\n",
        "num_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. モデルの構築\n",
        "model = Sequential()\n",
        "model.add(Masking(mask_value=0., input_shape=(max_length, num_features)))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 5. モデルのコンパイルと学習\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(\n",
        "    X_train_padded, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_padded, y_test)\n",
        ")\n",
        "\n",
        "# 6. モデルの評価\n",
        "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "\n",
        "# 7. 予測と結果の表示\n",
        "y_pred = model.predict(X_test_padded)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "y_pred_labels = label_encoder.inverse_transform(y_pred_classes)\n",
        "y_true_labels = label_encoder.inverse_transform(y_true_classes)\n",
        "print(classification_report(y_true_labels, y_pred_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 8. 特徴量の重要度評価（Permutation Feature Importance）\n",
        "\n",
        "# 8.1 ベースラインの性能を計算\n",
        "# テストデータでの予測\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# ベースラインのAccuracyを計算\n",
        "baseline_accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
        "print(f'Baseline Accuracy: {baseline_accuracy:.4f}')\n",
        "\n",
        "# 8.2 特徴量ごとの重要度を計算\n",
        "num_features = X_test.shape[2]\n",
        "feature_importances = []\n",
        "\n",
        "for feature_idx in range(num_features):\n",
        "    # テストデータをコピー\n",
        "    X_test_permuted = X_test.copy()\n",
        "\n",
        "    # 特徴量をランダムにシャッフル（サンプル間でシャッフル）\n",
        "    permuted_feature = X_test_permuted[:, :, feature_idx].reshape(X_test_permuted.shape[0], -1)\n",
        "    np.random.shuffle(permuted_feature)\n",
        "    X_test_permuted[:, :, feature_idx] = permuted_feature.reshape(X_test_permuted.shape[0], X_test_permuted.shape[1])\n",
        "\n",
        "    # シャッフル後のデータで予測\n",
        "    y_pred_permuted = model.predict(X_test_permuted)\n",
        "    y_pred_classes_permuted = np.argmax(y_pred_permuted, axis=1)\n",
        "\n",
        "    # シャッフル後のAccuracyを計算\n",
        "    permuted_accuracy = accuracy_score(y_true_classes, y_pred_classes_permuted)\n",
        "\n",
        "    # 性能の差を計算（重要度）\n",
        "    importance = baseline_accuracy - permuted_accuracy\n",
        "    feature_importances.append(importance)\n",
        "    print(f'Feature {feature_idx + 1} Importance: {importance:.4f}')\n",
        "\n",
        "# 8.3 特徴量重要度の可視化\n",
        "feature_names = [f'Feature {i+1}' for i in range(num_features)]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(X[7].columns, feature_importances)\n",
        "plt.xlabel('Decrease in Accuracy')\n",
        "plt.title('Permutation Feature Importance')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "\n",
        "# SHAPの初期化\n",
        "shap.initjs()\n",
        "\n",
        "# GradientExplainerの作成\n",
        "explainer = shap.DeepExplainer(model, X_train)\n",
        "\n",
        "\n",
        "# テストデータに対するSHAP値の計算\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# 5. SHAP値の集約\n",
        "# 全クラスのSHAP値の絶対値を合計\n",
        "shap_values_sum = np.sum(np.abs(shap_values), axis=0)  # 形状: (サンプル数, タイムステップ数, 特徴量数)\n",
        "# サンプル数とタイムステップ数方向に平均\n",
        "mean_shap_values = np.mean(shap_values_sum, axis=(0, 1))  # 形状: (特徴量数,)\n",
        "\n",
        "# 6. 特徴量名の指定（必要に応じて変更）\n",
        "feature_names = [f'Feature {i+1}' for i in range(num_features)]\n",
        "\n",
        "# 7. 特徴量重要度のプロット\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_names, mean_shap_values)\n",
        "plt.xlabel('Mean Absolute SHAP Value')\n",
        "plt.title('Feature Importance based on SHAP values')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(X_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHbr81KP4EsX"
      },
      "outputs": [],
      "source": [
        "#  pickleファイルを読み込む\n",
        "with open('/Users/hinase/Downloads/Th-s/d_nakazawa_acc_check_segments4.7new.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "segx = data['d_nakazawa_check_segx']\n",
        "segy = data['d_nakazawa_check_segy']\n",
        "segz = data['d_nakazawa_check_segz']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "motion_data = mr.process_apple_watch_csv('/Users/hinase/Downloads/tri/MotionData_20240819_205216.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a simple sine wave as an example of a waveform or signal\n",
        "x = np.linspace(0, 10, 1000)\n",
        "y = np.sin(x)\n",
        "\n",
        "# Define the sections to be colored\n",
        "color_sections = [(200, 300, 'red'), (450, 550, 'blue'), (700, 800, 'red')]\n",
        "\n",
        "# Plot the entire waveform in gray\n",
        "plt.figure(figsize=(10, 2))\n",
        "plt.plot(x, y, color='gray', linewidth=3)\n",
        "\n",
        "# Highlight the specified sections with the chosen colors\n",
        "for start, end, color in color_sections:\n",
        "    plt.plot(x[start:end], y[start:end], color=color, linewidth=5)\n",
        "\n",
        "# Add an arrow to indicate the flow of data\n",
        "# plt.annotate('', xy=(10, 0), xytext=(0, 0),\n",
        "#              arrowprops=dict(facecolor='black', shrink=0.05, width=2))\n",
        "plt.xticks(color=\"None\")\n",
        "plt.yticks(color=\"None\")\n",
        "plt.tick_params(length=0)\n",
        "# Remove axes for a cleaner look\n",
        "plt.axis('off')\n",
        "plt.savefig(\"/Users/hinase/Downloads/plt.svg\")\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cairosvg\n",
        "\n",
        "# SVGファイルのパス\n",
        "input_svg_path = \"/Users/hinase/Downloads/ss.svg\"\n",
        "# 出力するEPSファイルのパス\n",
        "output_eps_path = \"/Users/hinase/Downloads/ss.eps\"\n",
        "\n",
        "# SVGをEPSに変換\n",
        "cairosvg.svg2eps(url=input_svg_path, write_to=output_eps_path)\n",
        "\n",
        "print(f\"SVG画像がEPS形式で '{output_eps_path}' に保存されました。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import openpyxl\n",
        "from natsort import natsorted\n",
        "\n",
        "\n",
        "\n",
        "folder_path = '/Users/hinase/Downloads/folder1'\n",
        "folder_2_path = '/Users/hinase/Downloads/folder2'\n",
        "\n",
        "\n",
        "# Excelファイル名リストを自然順で取得\n",
        "files = natsorted(os.listdir(folder_path))\n",
        "\n",
        "#ファイル名リストをfor文でまわして各ファイルの絶対パスを構築\n",
        "for filename in files:\n",
        "    filepath = os.path.join(folder_path, filename)\n",
        "\n",
        "    # xlsxファイルにアクセス→先頭シートのオブジェクトを取得\n",
        "    wb = openpyxl.load_workbook(filepath)\n",
        "    ws_name = wb.sheetnames[0]\n",
        "    ws = wb[ws_name]\n",
        "\n",
        "    # csvに変換して、folder2に保存\n",
        "    savecsv_path = os.path.join(folder_2_path, filename.rstrip(\".xlsx\")+\".csv\")\n",
        "    with open(savecsv_path, 'w', newline=\"\") as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        for row in ws.rows:\n",
        "            writer.writerow([cell.value for cell in row])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
