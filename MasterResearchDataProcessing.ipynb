{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGJb1ScIJE-J"
   },
   "outputs": [],
   "source": [
    "# Google Colabでライブラリをアップロードする\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FI3b2MALJQG9"
   },
   "outputs": [],
   "source": [
    "# Google Colabでドライブのデータを使う\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5P9aOSopJUiL"
   },
   "outputs": [],
   "source": [
    "# Google Colabでライブラリをインストールする\n",
    "!pip install japanize_matplotlib bottleneck tslearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Lq-ZkyCJJbu"
   },
   "outputs": [],
   "source": [
    "# 自作関数\n",
    "import MasterResearchFunction as mr\n",
    "\n",
    "# 基本ライブラリ\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import statistics\n",
    "from datetime import datetime, timedelta\n",
    "from decimal import Decimal\n",
    "\n",
    "# 数値計算とデータ処理\n",
    "import bottleneck as bn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 機械学習ライブラリ\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# ディープラーニングライブラリ\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Activation,\n",
    "    Add,\n",
    "    Conv1D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    GlobalAveragePooling1D,\n",
    "    Input,\n",
    "    LayerNormalization,\n",
    "    LSTM,\n",
    "    Masking,\n",
    "    MaxPooling1D,\n",
    "    MultiHeadAttention,\n",
    ")\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# プロットと可視化\n",
    "import japanize_matplotlib\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# その他のライブラリ\n",
    "from fastdtw import fastdtw\n",
    "from scipy import signal, stats\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.spatial.distance import euclidean\n",
    "from tslearn.metrics import dtw_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#motion_data = mr.process_apple_watch_csv('/Users/hinase/CodeChord/MasterResearch/datasets/new/nakazawa/motion/raw/nakazawa_eat.csv')\n",
    "eye_data = mr.process_tobii_csv('datasets/new/mizuno/eye/raw/mizuno1_eat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25秒減算坂本\n",
    "#eye_data[\"Timestamp\"] = eye_data[\"Timestamp\"] - pd.to_timedelta(25.659, unit='s')\n",
    "#eye_data[\"Timestamp\"] = eye_data[\"Timestamp\"] - pd.to_timedelta(25.4841, unit='s')\n",
    "#eye_data[\"Timestamp\"] = eye_data[\"Timestamp\"] - pd.to_timedelta(22.831, unit='s')\n",
    "# 29秒減算渡部\n",
    "#eye_data[\"Timestamp\"] = eye_data[\"Timestamp\"] - pd.to_timedelta(29.644, unit='s')\n",
    "# 43秒減算小寺\n",
    "#eye_data[\"Timestamp\"] = eye_data[\"Timestamp\"] - pd.to_timedelta(43.0029, unit='s')\n",
    "# 43秒減算小寺(tri, check)\n",
    "#eye_data[\"Timestamp\"] = eye_data[\"Timestamp\"] - pd.to_timedelta(42.045, unit='s')\n",
    "#eye_data[\"Timestamp\"] = eye_data[\"Timestamp\"] - pd.to_timedelta(42.958, unit='s')\n",
    "# 43秒減算中沢（circle, tri）\n",
    "eye_data[\"Timestamp\"] = eye_data[\"Timestamp\"] - pd.to_timedelta(38.43, unit='s')\n",
    "# 43秒減算中沢（cross）\n",
    "#eye_data[\"Timestamp\"] = eye_data[\"Timestamp\"] + pd.to_timedelta(11.486, unit='s')\n",
    "#eye_data[\"Timestamp\"] = eye_data[\"Timestamp\"] - pd.to_timedelta(43.66, unit='s')\n",
    "# 43秒減算水野（cross）\n",
    "#eye_data[\"Timestamp\"] = eye_data[\"Timestamp\"] - pd.to_timedelta(2.043, unit='s')\n",
    "# 43秒減算水野（tri）\n",
    "#eye_data[\"Timestamp\"] = eye_data[\"Timestamp\"] - pd.to_timedelta(2.171, unit='s')\n",
    "# 43秒減算水野（circle, check）\n",
    "#eye_data[\"Timestamp\"] = eye_data[\"Timestamp\"] - pd.to_timedelta(1.994, unit='s')\n",
    "#eye_data[\"Timestamp\"] = eye_data[\"Timestamp\"] - pd.to_timedelta(0.1, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(eye_data[\"Timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_data[\"Timestamp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Timestamp('2024-10-10 16:00:14.060896873')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hinase_circle_seg = mr.three_axis_spring(motion_data, train_data, [5, 5, 5], 'acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hz = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mr.find_true_intervals(motion_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_data[\"Timestamp\"][30895]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.append([a[i][0]+80, a[i][1]-130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del b[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(b)):\n",
    "  print(b[j][1] - b[j][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a)):\n",
    "  print(a[i][1] - a[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del b[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = []\n",
    "for i in range(len(b)):\n",
    "  c.append([motion_data[\"Timestamp\"][b[i][0]], motion_data[\"Timestamp\"][b[i][1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各範囲内のデータを格納するリストを用意します\n",
    "result = []\n",
    "# cの各行に対してループを回します\n",
    "for start_time, end_time in extracted_data:\n",
    "    # 範囲内のデータを抽出するためのマスクを作成します\n",
    "    mask = (eye_data[\"Timestamp\"] >= start_time) & (eye_data[\"Timestamp\"] <= end_time)\n",
    "    # マスクを適用してデータを抽出します\n",
    "    data_in_range = eye_data.loc[mask]\n",
    "    # 結果をリストに追加します\n",
    "    result.append(data_in_range)\n",
    "\n",
    "# 結果を確認します\n",
    "for idx, data in enumerate(result):\n",
    "    print(f\"範囲 {idx+1}:\")\n",
    "    print(data)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定数の定義\n",
    "\n",
    "LABELS = ['circle', 'cross', 'tri', 'check']\n",
    "COLUMNS_TO_DROP = [\n",
    "    'Sensor', 'Participant name', 'Event', 'Event value',\n",
    "    'Eye movement type', 'Eye movement type index', 'Ungrouped',\n",
    "    'Validity left', 'Validity right', 'Gaze event duration', 'Gaze2D_Distance',\n",
    "    'Fixation_Distance', 'Gaze3D_Distance', 'Pupil_Diameter_Change',\n",
    "    'GazeDirection_Distance', 'PupilPosition_Distance'\n",
    "]\n",
    "# インターバルのパラメータ設定\n",
    "MIN_INTERVAL = 0.84  # 最小インターバル長（秒）\n",
    "MAX_INTERVAL = 3.04  # 最大インターバル長（秒）\n",
    "NUM_INTERVALS = 160  # 抽出するインターバルの数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in NAMES:\n",
    "    print(f\"Processing {name}...\")\n",
    "\n",
    "    # データの読み込みと前処理\n",
    "    eye_data, gesture_labels = mr.load_gesture_eye_data_pickle(name, LABELS, COLUMNS_TO_DROP)\n",
    "    # 変数に保存\n",
    "    globals()[f'{name}_eye'] = eye_data\n",
    "    globals()[f'{name}_label'] = gesture_labels\n",
    "    globals()[f'{name}_true_label'] = ['gesture'] * len(eye_data)\n",
    "\n",
    "    # モーションデータとアイデータの読み込みと前処理\n",
    "    motion_routine_data, eye_routine_data = mr.load_motion_and_eye_data(name)\n",
    "    # 変数に保存\n",
    "    globals()[f'{name}_motion_routine'] = motion_routine_data\n",
    "    globals()[f'{name}_eye_routine'] = eye_routine_data\n",
    "\n",
    "    # 'Timestamp' カラムの存在と型を確認\n",
    "    assert 'Timestamp' in motion_routine_data.columns, f\"{name}_motion_routineに'Timestamp'がありません。\"\n",
    "    assert motion_routine_data['Timestamp'].dtype == 'datetime64[ns]', f\"{name}_motion_routineの'Timestamp'がdatetime64[ns]ではありません。\"\n",
    "    assert 'Timestamp' in eye_routine_data.columns, f\"{name}_eye_routineに'Timestamp'がありません。\"\n",
    "    assert eye_routine_data['Timestamp'].dtype == 'datetime64[ns]', f\"{name}_eye_routineの'Timestamp'がdatetime64[ns]ではありません。\"\n",
    "\n",
    "    # 既に読み込んだモーションデータを使用\n",
    "    motion_data = motion_routine_data\n",
    "\n",
    "    # 除外インターバルの取得\n",
    "    exclusion_intervals = mr.get_exclusion_intervals(motion_data)\n",
    "\n",
    "    # データ全体の時間範囲の取得\n",
    "    start_time = motion_routine_data['Timestamp'].min()\n",
    "    end_time = motion_routine_data['Timestamp'].max()\n",
    "\n",
    "    # 利用可能なインターバルの取得\n",
    "    available_intervals = mr.get_available_intervals(exclusion_intervals, start_time, end_time)\n",
    "\n",
    "    print(f\"{name} の利用可能なインターバル数: {len(available_intervals)}\")\n",
    "\n",
    "    # ランダムなインターバルの抽出（eye_routine_data を使用）\n",
    "    extracted_data = mr.extract_random_intervals(\n",
    "        eye_routine_data, available_intervals, MIN_INTERVAL, MAX_INTERVAL, NUM_INTERVALS\n",
    "    )\n",
    "\n",
    "    # 抽出されたデータを変数に保存\n",
    "    globals()[f'{name}_extracted_intervals'] = extracted_data\n",
    "    globals()[f'{name}_false_label'] = ['non_gesture'] * len(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mizuno_motion_routine['Timestamp'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mizuno_eye_routine['Timestamp'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データとラベルを格納するリストの初期化\n",
    "X = []\n",
    "y_labels = []\n",
    "true_labels = []\n",
    "\n",
    "for name in NAMES:\n",
    "    # ジェスチャーの目のデータと対応するラベルを取得\n",
    "    eye_data = globals()[f'{name}_eye']  # リスト形式のデータフレーム\n",
    "    gesture_labels = globals()[f'{name}_label']  # 個別のジェスチャーラベル\n",
    "    true_label_gesture = globals()[f'{name}_true_label']  # ['gesture'] * len(eye_data)\n",
    "\n",
    "    # シーケンスが空でないか確認しながらデータを追加\n",
    "    for seq, lbl, true_lbl in zip(eye_data, gesture_labels, true_label_gesture):\n",
    "        if seq is not None and len(seq) > 0:\n",
    "            X.append(seq)\n",
    "            y_labels.append(lbl)\n",
    "            true_labels.append(true_lbl)\n",
    "        else:\n",
    "            print(f\"{name} のジェスチャーシーケンスが空です。対応するラベルをスキップします。\")\n",
    "\n",
    "    # 非ジェスチャーの目のデータと対応するラベルを取得\n",
    "    extracted_data = globals()[f'{name}_extracted_intervals']  # リスト形式のデータフレーム\n",
    "    false_labels = globals()[f'{name}_false_label']  # ['non_gesture'] * len(extracted_data)\n",
    "    true_label_non_gesture = globals()[f'{name}_false_label']  # ['non_gesture'] * len(extracted_data)\n",
    "\n",
    "    # シーケンスが空でないか確認しながらデータを追加\n",
    "    for seq, lbl, true_lbl in zip(extracted_data, false_labels, true_label_non_gesture):\n",
    "        if seq is not None and len(seq) > 0:\n",
    "            X.append(seq)\n",
    "            y_labels.append(lbl)\n",
    "            true_labels.append(true_lbl)\n",
    "        else:\n",
    "            print(f\"{name} の非ジェスチャーシーケンスが空です。対応するラベルをスキップします。\")\n",
    "\n",
    "# データの長さを確認\n",
    "print(f\"総データ数: {len(X)}\")\n",
    "print(f\"総ラベル数（y_labels）: {len(y_labels)}\")\n",
    "print(f\"総真偽ラベル数（true_labels）: {len(true_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = []\n",
    "for i in range(len(X)):\n",
    "  length.append(len(X[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =[]\n",
    "X.extend(sakamoto_eye)\n",
    "X.extend(watabe_eye)\n",
    "X.extend(nakazawa_eye)\n",
    "X.extend(kotera_eye)\n",
    "X.extend(mizuno_eye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "label.extend(sakamoto_label)\n",
    "label.extend(watabe_label)\n",
    "label.extend(nakazawa_label)\n",
    "label.extend(kotera_label)\n",
    "label.extend(mizuno_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filled = []\n",
    "X_scaled = []\n",
    "for idx, sequence in enumerate(X):\n",
    "    df = pd.DataFrame(sequence)\n",
    "    # 欠損値の補間と補完\n",
    "    df = df.interpolate(method='linear', limit_direction='both', axis=0)\n",
    "    df = df.fillna(method='ffill')\n",
    "    df = df.fillna(method='bfill')\n",
    "    # 残る NaN を 0 で埋める\n",
    "    if df.isnull().values.any():\n",
    "        print(f\"シーケンス {idx} にまだ NaN が存在します。0 で埋めます。\")\n",
    "        df = df.fillna(0)\n",
    "    # データ型を数値型に変換（必要に応じて）\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    X_filled.append(df.values)\n",
    "\n",
    "# スケーリング前に NaN をチェック\n",
    "for idx, sequence in enumerate(X_filled):\n",
    "    if np.isnan(sequence).any():\n",
    "        print(f\"シーケンス {idx} に NaN が残っています。スケーリングをスキップします。\")\n",
    "        continue\n",
    "    if sequence.shape[0] > 0:\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled.append(scaler.fit_transform(sequence))\n",
    "    else:\n",
    "        print(f\"シーケンス {idx} は空です。スケーリングをスキップします。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ラベルのエンコーディング\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(label)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "y_categorical = to_categorical(y_encoded, num_classes=num_classes)\n",
    "\n",
    "# 2. データの分割（パディングの前に行う）\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_categorical, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 3. 訓練データとテストデータでそれぞれ最大シーケンス長を計算\n",
    "max_length_train = max(len(seq) for seq in X_train_raw)\n",
    "max_length_test = max(len(seq) for seq in X_test_raw)\n",
    "max_length = max(max_length_train, max_length_test)\n",
    "\n",
    "# 4. シーケンスのパディング\n",
    "X_train_padded = pad_sequences(X_train_raw, maxlen=max_length, padding='post', value=0.0, dtype='float32')\n",
    "X_test_padded = pad_sequences(X_test_raw, maxlen=max_length, padding='post', value=0.0, dtype='float32')\n",
    "\n",
    "# 5. パディング後のデータに NaN が含まれていないか確認\n",
    "print('NaN in X_train_padded:', np.isnan(X_train_padded).any())\n",
    "print('NaN in X_test_padded:', np.isnan(X_test_padded).any())\n",
    "\n",
    "# 必要に応じて NaN を 0 で置換\n",
    "if np.isnan(X_train_padded).any():\n",
    "    X_train_padded = np.nan_to_num(X_train_padded, nan=0.0)\n",
    "if np.isnan(X_test_padded).any():\n",
    "    X_test_padded = np.nan_to_num(X_test_padded, nan=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of samples in X_scaled: {len(X_scaled)}')\n",
    "print(f'Number of samples in y_categorical: {len(y_categorical)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量数を取得\n",
    "num_features = X_train_padded.shape[2]\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. モデルの構築\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0., input_shape=(max_length, num_features)))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "# 5. モデルのコンパイルと学習\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "    X_train_padded, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_padded, y_test)\n",
    ")\n",
    "\n",
    "# 6. モデルの評価\n",
    "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "# 7. 予測と結果の表示\n",
    "y_pred = model.predict(X_test_padded)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred_classes)\n",
    "y_true_labels = label_encoder.inverse_transform(y_true_classes)\n",
    "print(classification_report(y_true_labels, y_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (max_length, num_features)\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Masking(mask_value=0.)(inputs)\n",
    "\n",
    "# num_featuresを定義（入力データの特徴量の次元数）\n",
    "num_features = input_shape[1]\n",
    "\n",
    "# Transformerブロックの定義\n",
    "def transformer_block(x, num_heads, key_dim, ff_dim, rate=0.1):\n",
    "    # マルチヘッド注意機構\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(x, x)\n",
    "    attn_output = Dropout(rate)(attn_output)\n",
    "\n",
    "    # 出力次元をnum_featuresに変換\n",
    "    attn_output = Dense(num_features)(attn_output)\n",
    "\n",
    "    out1 = Add()([x, attn_output])\n",
    "    out1 = LayerNormalization(epsilon=1e-6)(out1)\n",
    "\n",
    "    # フィードフォワードネットワーク\n",
    "    ffn_output = Dense(ff_dim, activation='relu')(out1)\n",
    "\n",
    "    # 出力次元をnum_featuresに変換\n",
    "    ffn_output = Dense(num_features)(ffn_output)\n",
    "\n",
    "    ffn_output = Dropout(rate)(ffn_output)\n",
    "    out2 = Add()([out1, ffn_output])\n",
    "    out2 = LayerNormalization(epsilon=1e-6)(out2)\n",
    "    return out2\n",
    "\n",
    "# Transformerブロックの適用\n",
    "x = transformer_block(x, num_heads=4, key_dim=64, ff_dim=128)\n",
    "\n",
    "# プーリングと出力層\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "outputs = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "# モデルの作成\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. モデルのコンパイルと学習\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "    X_train_padded, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_padded, y_test)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. モデルの評価\n",
    "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "# 7. 予測と結果の表示\n",
    "y_pred = model.predict(X_test_padded)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred_classes)\n",
    "y_true_labels = label_encoder.inverse_transform(y_true_classes)\n",
    "print(classification_report(y_true_labels, y_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 8. 特徴量の重要度評価（Permutation Feature Importance）\n",
    "\n",
    "# 8.1 ベースラインの性能を計算\n",
    "# テストデータでの予測\n",
    "y_pred = model.predict(X_test_padded)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# ベースラインのAccuracyを計算\n",
    "baseline_accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "print(f'Baseline Accuracy: {baseline_accuracy:.4f}')\n",
    "\n",
    "# 8.2 特徴量ごとの重要度を計算\n",
    "num_features = X_test_padded.shape[2]\n",
    "feature_importances = []\n",
    "\n",
    "for feature_idx in range(num_features):\n",
    "    # テストデータをコピー\n",
    "    X_test_permuted = X_test_padded.copy()\n",
    "\n",
    "    # 特徴量をランダムにシャッフル（サンプル間でシャッフル）\n",
    "    permuted_feature = X_test_permuted[:, :, feature_idx].reshape(X_test_permuted.shape[0], -1)\n",
    "    np.random.shuffle(permuted_feature)\n",
    "    X_test_permuted[:, :, feature_idx] = permuted_feature.reshape(X_test_permuted.shape[0], X_test_permuted.shape[1])\n",
    "\n",
    "    # シャッフル後のデータで予測\n",
    "    y_pred_permuted = model.predict(X_test_permuted)\n",
    "    y_pred_classes_permuted = np.argmax(y_pred_permuted, axis=1)\n",
    "\n",
    "    # シャッフル後のAccuracyを計算\n",
    "    permuted_accuracy = accuracy_score(y_true_classes, y_pred_classes_permuted)\n",
    "\n",
    "    # 性能の差を計算（重要度）\n",
    "    importance = baseline_accuracy - permuted_accuracy\n",
    "    feature_importances.append(importance)\n",
    "    print(f'Feature {feature_idx + 1} Importance: {importance:.4f}')\n",
    "\n",
    "# 8.3 特徴量重要度の可視化\n",
    "feature_names = [f'Feature {i+1}' for i in range(num_features)]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(X[7].columns, feature_importances)\n",
    "plt.xlabel('Decrease in Accuracy')\n",
    "plt.title('Permutation Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WHbr81KP4EsX"
   },
   "outputs": [],
   "source": [
    "#  pickleファイルを読み込む\n",
    "with open('/Users/hinase/Downloads/Th-s/d_nakazawa_acc_check_segments4.7new.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "segx = data['d_nakazawa_check_segx']\n",
    "segy = data['d_nakazawa_check_segy']\n",
    "segz = data['d_nakazawa_check_segz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple sine wave as an example of a waveform or signal\n",
    "x = np.linspace(0, 10, 1000)\n",
    "y = np.sin(x)\n",
    "\n",
    "# Define the sections to be colored\n",
    "color_sections = [(200, 300, 'red'), (450, 550, 'blue'), (700, 800, 'red')]\n",
    "\n",
    "# Plot the entire waveform in gray\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.plot(x, y, color='gray', linewidth=3)\n",
    "\n",
    "# Highlight the specified sections with the chosen colors\n",
    "for start, end, color in color_sections:\n",
    "    plt.plot(x[start:end], y[start:end], color=color, linewidth=5)\n",
    "\n",
    "# Add an arrow to indicate the flow of data\n",
    "# plt.annotate('', xy=(10, 0), xytext=(0, 0),\n",
    "#              arrowprops=dict(facecolor='black', shrink=0.05, width=2))\n",
    "plt.xticks(color=\"None\")\n",
    "plt.yticks(color=\"None\")\n",
    "plt.tick_params(length=0)\n",
    "# Remove axes for a cleaner look\n",
    "plt.axis('off')\n",
    "#plt.savefig(\"/Users/hinase/Downloads/plt.svg\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cairosvg\n",
    "\n",
    "# SVGファイルのパス\n",
    "input_svg_path = \"/Users/hinase/Downloads/ss.svg\"\n",
    "# 出力するEPSファイルのパス\n",
    "output_eps_path = \"/Users/hinase/Downloads/ss.eps\"\n",
    "\n",
    "# SVGをEPSに変換\n",
    "cairosvg.svg2eps(url=input_svg_path, write_to=output_eps_path)\n",
    "\n",
    "print(f\"SVG画像がEPS形式で '{output_eps_path}' に保存されました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import openpyxl\n",
    "from natsort import natsorted\n",
    "\n",
    "folder_path = '/Users/hinase/Downloads/folder3'\n",
    "folder_2_path = '/Users/hinase/Downloads/folder4'\n",
    "\n",
    "# Get Excel file names in natural order, filtering only supported Excel files\n",
    "supported_extensions = ('.xlsx', '.xlsm', '.xltx', '.xltm')\n",
    "files = natsorted([f for f in os.listdir(folder_path) if f.endswith(supported_extensions)])\n",
    "\n",
    "# Loop over filenames and build absolute path for each file\n",
    "for filename in files:\n",
    "    filepath = os.path.join(folder_path, filename)\n",
    "\n",
    "    # Access xlsx file and get the first sheet object\n",
    "    wb = openpyxl.load_workbook(filepath)\n",
    "    ws_name = wb.sheetnames[0]\n",
    "    ws = wb[ws_name]\n",
    "\n",
    "    # Convert to csv and save to folder4\n",
    "    savecsv_path = os.path.join(folder_2_path, filename.rstrip(\".xlsx\") + \".csv\")\n",
    "    with open(savecsv_path, 'w', newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for row in ws.rows:\n",
    "            writer.writerow([cell.value for cell in row])\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
